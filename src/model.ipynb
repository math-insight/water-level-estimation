{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import max_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.read_pickle(r\"../data/B00020S.pkl\")\n",
    "data['Date'] = pd.to_datetime(data['Date'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODO\n",
    " - znaleźć prawidłowe offset_values — Max **DONE**\n",
    " - wykresy błędów — Adam\n",
    " - nałożyć wartość bezwzględną na histogram błędu bezwzględnego — Adam\n",
    " - upiększyć wykresy — Max\n",
    " - dodać do temp kolumnę z datami — Max\n",
    " - może jakiś opis matematyczny w markdownie tej regresji czy coś — Max albo Adam\n",
    " - zautomatyzować dobór offset_values - Max"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Stacje\n",
    "stations = ['GŁOGÓW', 'ŚCINAWA', 'MALCZYCE', 'BRZEG DOLNY', 'OŁAWA', 'BRZEG', 'KRAPKOWICE', 'RACIBÓRZ-MIEDONIA', 'KRZYŻANOWICE', 'OLZA', 'CHAŁUPKI']\n",
    "\n",
    "# Lista różnic w dniach między Głogowem a kolejną stacją\n",
    "offset_values = [0, 1, 1, 1, 2, 2, 3, 3, 3, 3]\n",
    "\n",
    "# Rok, od którego chcemy trenować i testować model\n",
    "start_year = 2019\n",
    "\n",
    "# Grupowanie po dniach i stacjach\n",
    "data_grouped = data.groupby(['Date', 'Station'])['B00020S'].mean().reset_index()\n",
    "\n",
    "# Osobny dataframe dla każdej stacji i tylko rekordy od danego roku\n",
    "station_datas = [data_grouped[(data_grouped['Station'] == station) & (data_grouped['Date'].dt.year >= start_year)].reset_index() for station in stations]\n",
    "\n",
    "# Połączenie kolumn z poziomem wody z każdej stacji w jeden dataframe\n",
    "temp = pd.concat([station_data['B00020S'] for station_data in station_datas], axis='columns').reset_index(drop=True)\n",
    "\n",
    "# Zmiana nazw kolumn\n",
    "temp.columns = stations\n",
    "\n",
    "# Przesunięcie każdej kolumny o odpowiednią liczbę dni\n",
    "for i, col in enumerate(temp.columns):\n",
    "    temp[col] = temp[col].shift(periods=-offset_values[i])\n",
    "\n",
    "# Usunięcie NA, możliwe, że później można to dopracować\n",
    "temp = temp.dropna()\n",
    "\n",
    "# Zmienne służące do podziału zbioru danych na zbiór treningowy i zbiór testujący\n",
    "test_proportion = 0.2\n",
    "train_proportion = 1 - test_proportion\n",
    "split_point = int(len(temp) * train_proportion)\n",
    "\n",
    "# Podział na zbiór treningowy i zbiór testowy\n",
    "train_data, test_data = temp.iloc[:split_point], temp.iloc[split_point:]\n",
    "\n",
    "# Zmienne niezależne\n",
    "x = train_data.iloc[:, 1:]\n",
    "x = sm.add_constant(x)\n",
    "\n",
    "# Zmienna niezależna\n",
    "y = train_data.iloc[:, 0]\n",
    "\n",
    "# Dopasowanie modelu\n",
    "model = sm.OLS(y, x).fit()\n",
    "\n",
    "# Podsumowanie\n",
    "print(model.summary())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Dataframe z resztami modelu\n",
    "residuals = pd.DataFrame(model.resid)\n",
    "\n",
    "# Wykres reszt\n",
    "residuals.plot()\n",
    "\n",
    "# Wykres gęstości jądra reszt / rozkład prawdopodobieństwa reszt\n",
    "residuals.plot(kind='kde')\n",
    "\n",
    "# Statystyki opisowe reszt\n",
    "print(residuals.describe())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Przewidywanie wartości na podstawie modelu\n",
    "model.predict(x)\n",
    "\n",
    "# To samo co wyżej, ale ręcznie\n",
    "test_values = model.params['const'] + sum(model.params[param] * test_data[param] for param in model.params.index[1:])\n",
    "\n",
    "# Tymczasowa oś X, trzeba będzie zmienić na prawdziwą datę\n",
    "date_train = np.arange(0, len(train_data))\n",
    "date_test = np.arange(len(train_data), len(train_data) + len(test_data))\n",
    "\n",
    "# Ustawienie rozmiaru całego wykresu (jednostki są w calach\n",
    "plt.figure(figsize=(36, 16))\n",
    "\n",
    "# Prawdziwe dane treningowe\n",
    "plt.plot(date_train, train_data.iloc[:,0], 'b', label='faktyczne dane', linewidth=3)\n",
    "\n",
    "# Dane treningowe modelu\n",
    "plt.plot(date_train, model.predict(), 'r', label='model', linewidth=3)\n",
    "\n",
    "# Prawdziwe dane testowe\n",
    "plt.plot(date_test, test_data.iloc[:, 0], 'g', label='faktyczne dane (test)', linewidth=3)\n",
    "\n",
    "# Dane testowe modelu\n",
    "plt.plot(date_test, test_values, 'm', label='model (test)', linewidth=3)\n",
    "\n",
    "# Granice osi X i Y wykresu\n",
    "plt.xlim(0, len(date_train) + len(date_test))\n",
    "plt.ylim(0, 1000)\n",
    "\n",
    "# Parametry wykresu\n",
    "plt.legend(loc='upper right', fontsize=20)\n",
    "plt.title(\"Coś tam coś tam, nwm Adam nazwie\", fontsize=30)\n",
    "plt.xlabel('Miesiąc (xD)', fontsize=15)\n",
    "plt.ylabel('Poziom wody (cm)', fontsize=15)\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Prawdziwe dane testowe\n",
    "y_true = test_data.iloc[:, 0]\n",
    "\n",
    "# Średni błąd kwadratowy\n",
    "mse = mean_squared_error(y_true=y_true, y_pred=test_values, squared=True)\n",
    "\n",
    "# Pierwiastek błędu kwadratowego\n",
    "rmse = mean_squared_error(y_true=y_true, y_pred=test_values, squared=False)\n",
    "\n",
    "# Błąd procentowy średniokwadratowy\n",
    "mape = mean_absolute_percentage_error(y_true=y_true, y_pred=test_values)\n",
    "\n",
    "# Maksymalny błąd\n",
    "max_error = max_error(y_true=y_true, y_pred=test_values)\n",
    "\n",
    "# Wyświetlenie wszystkich powyższych metryk\n",
    "print('Test MSE: %.3f' % mse)\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "print('Test MAPE: %.3f' % mape)\n",
    "print('Test max error: %.3f' % max_error)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Funkcja do liczenia korelacji Pearsona między dwiema stacjami\n",
    "def correlation_between_stations(station_1, station_2, lag):\n",
    "    station_1_id = stations.index(station_1.upper())\n",
    "    station_2_id = stations.index(station_2.upper())\n",
    "    correlation = lagged_dfs[lag][station_1_id]['B00020S'].corr(lagged_dfs[0][station_2_id]['B00020S'])\n",
    "    return round(correlation, 3)\n",
    "\n",
    "# Stacje\n",
    "stations = ['GŁOGÓW', 'ŚCINAWA', 'MALCZYCE', 'BRZEG DOLNY', 'OŁAWA', 'BRZEG', 'KRAPKOWICE', 'RACIBÓRZ-MIEDONIA', 'KRZYŻANOWICE', 'OLZA', 'CHAŁUPKI']\n",
    "\n",
    "# Grupowanie po dniach i stacjach\n",
    "data_grouped = data.groupby(['Date', 'Station'])['B00020S'].mean().reset_index()\n",
    "\n",
    "# Maksymalny lag\n",
    "max_lag = 7\n",
    "\n",
    "# Lista od 0 do max_lag\n",
    "lags = range(max_lag + 1)\n",
    "\n",
    "# Dwuwymiarowa lista zlagowanych dataframe'ów stacji\n",
    "# Dostęp do wybranej stacji i lagu: lagged_dfs[lag][id_stacji np. 0 dla Głogowa]\n",
    "start_date = '2008-01-08'\n",
    "end_date = '2023-09-30'\n",
    "lagged_dfs =[[data_grouped[(data_grouped['Date']\n",
    "                .between(\n",
    "                    pd.to_datetime(start_date) - pd.DateOffset(days=lag),\n",
    "                    pd.to_datetime(end_date) - pd.DateOffset(days=lag)\n",
    "                ))&(data_grouped['Station'] == station)].reset_index(drop=True) for station in stations]for lag in lags\n",
    "             ]\n",
    "# Lista stacji, dla których chcemy obliczyć korelację Pearsona względem Głogowa\n",
    "stations_to_calculate_corr = ['ŚCINAWA', 'MALCZYCE']\n",
    "\n",
    "# Wyświetlanie korelacji Pearsona\n",
    "for station in stations_to_calculate_corr:\n",
    "    print(f\"\\nWspółczynnik korelacji Pearsona liczony na podstawie poziomu wody w stacjach: {station.capitalize()} - Głogów\")\n",
    "    for lag in lags:\n",
    "        print(f\"Lag: {lag}, p = {correlation_between_stations(station, 'Głogów', lag)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
