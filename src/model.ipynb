{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import max_error\n",
    "from matplotlib.dates import DateFormatter, MonthLocator, YearLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(r\"../data/B00020S.pkl\")\n",
    "data['Date'] = pd.to_datetime(data['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tworzenie zbioru treningowego i testowego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wartości przesunięcia w czasie względem stacji w Głogowie zostały wybrane na podstawie ręcznej analizy różnicy czasu pomiędzy peakami poziomu wody w poszczególnych stacjach oraz na podstawie współczynników korelacji Pearsona (pod uwagę brany był najwyższy współczynnik oraz te bardzo bliskie najwyższego). Głównym celem była minimalizacja AIC, pod uwagę były brane przesunięcia odpowiadające najwyższym współczynnikom lub tym bardzo blisko najwyższych, jak również nieuwzględnianie danej stacji w ogóle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Słownik ze stacjami i odpowiadającymi im przesunięciom\n",
    "stations_offset_values_dict = {\n",
    "    'GŁOGÓW': 0,\n",
    "    'ŚCINAWA': 1,\n",
    "    'MALCZYCE': 1,\n",
    "    'BRZEG DOLNY': 1,\n",
    "    'OŁAWA': 2,\n",
    "    'BRZEG': 2,\n",
    "    'RACIBÓRZ-MIEDONIA': 3,\n",
    "    'KRZYŻANOWICE': 3,\n",
    "    'OLZA': 3,\n",
    "    'CHAŁUPKI': 3\n",
    "}\n",
    "\n",
    "# Stacje\n",
    "stations = ['GŁOGÓW', 'ŚCINAWA', 'MALCZYCE', 'BRZEG DOLNY', 'OŁAWA',  'BRZEG', 'RACIBÓRZ-MIEDONIA', 'KRZYŻANOWICE', 'OLZA', 'CHAŁUPKI']\n",
    "\n",
    "# Lista różnic w dniach między Głogowem a kolejną stacją\n",
    "offset_values = [stations_offset_values_dict[station] for station in stations]\n",
    "\n",
    "# Rok, od którego chcemy trenować i testować model\n",
    "start_year = 2019\n",
    "\n",
    "# Filtrowanie stacji i daty\n",
    "condition = ((data['Date'].dt.year >= start_year) & (data['Station'].isin(stations)))\n",
    "data_filtered = data[condition]\n",
    "\n",
    "# Data frame z kolumnami: Date i osobna kolumna dla każdej stacji zawierająca średni poziom wody w danym dniu\n",
    "station_data = pd.pivot_table(data_filtered, index=['Date'], columns=['Station'], values='B00020S', aggfunc='mean').reset_index()\n",
    "\n",
    "# Zmiana kolejności kolumn\n",
    "new_column_order = ['Date'] + stations\n",
    "station_data = station_data[new_column_order]\n",
    "\n",
    "# Przesunięcie każdej kolumny o ustaloną liczbę wierszy\n",
    "for i, col in enumerate(station_data.columns[1:]):\n",
    "    station_data[col] = station_data[col].shift(periods=-offset_values[i])\n",
    "\n",
    "# Usunięcia NA\n",
    "station_data = station_data.dropna()\n",
    "\n",
    "# Zmienne służące do podziału zbioru danych na zbiór treningowy i zbiór testujący\n",
    "test_proportion = 0.2\n",
    "train_proportion = 1 - test_proportion\n",
    "split_point = int(len(station_data) * train_proportion)\n",
    "\n",
    "# Podział na zbiór treningowy i zbiór testowy\n",
    "train_data, test_data = station_data.iloc[:split_point], station_data.iloc[split_point:]\n",
    "\n",
    "# Zmienne niezależne\n",
    "x = train_data.iloc[:, 1:]\n",
    "x = sm.add_constant(x)\n",
    "\n",
    "# Zmienna zależna\n",
    "y = train_data.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dopasowanie modelu i predykcja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zmienne niezależne\n",
    "x = train_data.iloc[:, 2:]\n",
    "x = sm.add_constant(x)\n",
    "\n",
    "# Zmienna zależna\n",
    "y = train_data.iloc[:, 1]\n",
    "\n",
    "# Dopasowanie modelu\n",
    "model = sm.OLS(y, x).fit()\n",
    "\n",
    "# Podsumowanie\n",
    "print(model.summary())\n",
    "# model.aic — zwraca wartość AIC\n",
    "\n",
    "# Przewidywanie wartości na podstawie modelu (zbiór treningowy)\n",
    "model_prediction = model.predict(x)\n",
    "\n",
    "# Przewidywanie wartości na podstawie modelu (zbiór testowy)\n",
    "x_test = test_data.iloc[:, 2:]\n",
    "x_test = sm.add_constant(x_test)\n",
    "test_prediction = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resztki modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykres wartości reszt przypomina wykres białego szumu, a wykres gęstości reszt przypomina gęstość rozkładu normalnego ze średnią 0, co jest jednym z argumentów świadczących za dobrym dopasowaniem modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe z resztami modelu\n",
    "residuals = pd.DataFrame(model.resid)\n",
    "\n",
    "# Okno wykresów\n",
    "fig, axes = plt.subplots(figsize=(36,32), ncols=1, nrows=2, gridspec_kw={'hspace': 0.3})\n",
    "months_locator = MonthLocator()\n",
    "months_fmt = DateFormatter(\"%b\")\n",
    "years_locator = YearLocator()\n",
    "years_fmt = DateFormatter(\"%Y\")\n",
    "\n",
    "# Wykres reszt\n",
    "axes[0].plot(station_data['Date'][:len(train_data)],residuals.iloc[:,0], linewidth=3)\n",
    "axes[0].set_xlim(station_data['Date'][:len(train_data)].min(), station_data['Date'][:len(train_data)].max())\n",
    "axes[0].set_xlabel('Data', fontsize=20)\n",
    "axes[0].set_title('Reszty', fontsize=30)\n",
    "axes[0].grid()\n",
    "axes[0].xaxis.set_minor_locator(months_locator)\n",
    "axes[0].xaxis.set_minor_formatter(months_fmt)\n",
    "axes[0].xaxis.set_major_locator(years_locator)\n",
    "axes[0].xaxis.set_major_formatter(years_fmt)\n",
    "axes[0].tick_params(axis='both', which='minor', labelsize=15)\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=20)\n",
    "plt.setp(axes[0].xaxis.get_minorticklabels(), rotation=45)\n",
    "plt.setp(axes[0].xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "# Wykres gęstości jądra reszt / rozkład prawdopodobieństwa reszt\n",
    "residuals.plot(kind='kde', ax=axes[1], linewidth=4)\n",
    "axes[1].set_xlim(-100, 100)\n",
    "axes[1].set_ylim(0, 0.03)\n",
    "axes[1].set_title('Wykres gęstości jądra / rozkładu prawdopodobieństwa reszt', fontsize=30)\n",
    "axes[1].set_ylabel('Gęstość', fontsize=20)\n",
    "axes[1].tick_params(axis='both', labelsize=15)\n",
    "axes[1].grid()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Statystyki opisowe reszt\n",
    "print(residuals.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metryki błędu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wśród metryk błędu znajdują się: błąd średniokwadratowy, pierwiastek z błędu średniokwadratowego, średni błąd względny, maksymalny błąd bezwzględny i względny. O ile mniejszy błąd najpewniej będzie oznaczać lepszy model, to należy zachować ostrożność przy interpretacji — np. dla pomiaru 40 cm i predykcji 50 cm, i dla pomiaru 400 cm i predykcji 500 cm błąd względny będzie taki sam, za to błąd bezwzględny czy kwadratowy będzie wyraźnie się różnić."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prawdziwe dane testowe\n",
    "y_true = test_data['GŁOGÓW']\n",
    "\n",
    "# Błąd średniokwadratowy\n",
    "mse = mean_squared_error(y_true=y_true, y_pred=test_prediction, squared=True)\n",
    "\n",
    "# Pierwiastek z błędu kwadratowego\n",
    "rmse = mean_squared_error(y_true=y_true, y_pred=test_prediction, squared=False)\n",
    "\n",
    "# Średni błąd względny\n",
    "mape = mean_absolute_percentage_error(y_true=y_true, y_pred=test_prediction)\n",
    "\n",
    "# Maksymalny błąd bezwzględny\n",
    "max_absolute_error = max_error(y_true=y_true, y_pred=test_prediction)\n",
    "\n",
    "# Maksymalny błąd względny\n",
    "max_relative_error = max(abs((test_data['GŁOGÓW'] - test_prediction) / test_data['GŁOGÓW']))\n",
    "\n",
    "# Bezwzględny błąd treningowy\n",
    "train_absolute_error = abs(train_data['GŁOGÓW'] - model_prediction)\n",
    "\n",
    "# Względny błąd treningowy\n",
    "train_relative_error = abs((train_data['GŁOGÓW'] - model_prediction) / train_data['GŁOGÓW'])\n",
    "\n",
    "# Bezwzględny błąd testowy\n",
    "test_absolute_error = abs(test_data['GŁOGÓW'] - test_prediction)\n",
    "\n",
    "# Względny błąd testowy\n",
    "test_relative_error = abs((test_data['GŁOGÓW'] - test_prediction) / test_data['GŁOGÓW'])\n",
    "\n",
    "# Wyświetlenie powyższych metryk wyliczonych dla predykcji względem zbioru testowego\n",
    "print('Test MSE: %.3f' % mse)\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "print('Test MAPE: %.4f' % mape)\n",
    "print('Test max absolute error: %.3f' % max_absolute_error)\n",
    "print('Test max relative error: %.4f' % max_relative_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wykresy predykcji, błędu bezwzględnego i błędu względnego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcja do ustawiania własności wykresu\n",
    "def set_common_plot_properties(axes_id, title, y_label):\n",
    "    axes[axes_id].set_xlabel('Data', fontsize=15)\n",
    "    axes[axes_id].set_ylabel(y_label, fontsize=15)\n",
    "    axes[axes_id].set_xlim(train_dates.min(), test_dates.max())\n",
    "    axes[axes_id].set_title(title, fontsize=30)\n",
    "    axes[axes_id].legend(loc='upper right', fontsize=20)\n",
    "    axes[axes_id].grid()\n",
    "    axes[axes_id].xaxis.set_minor_locator(months_locator)\n",
    "    axes[axes_id].xaxis.set_minor_formatter(months_fmt)\n",
    "    axes[axes_id].xaxis.set_major_locator(years_locator)\n",
    "    axes[axes_id].xaxis.set_major_formatter(years_fmt)\n",
    "    axes[axes_id].tick_params(axis='both', which='minor', labelsize=15)\n",
    "    axes[axes_id].tick_params(axis='both', which='major', labelsize=20)\n",
    "    plt.setp(axes[axes_id].xaxis.get_minorticklabels(), rotation=45)\n",
    "    plt.setp(axes[axes_id].xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "# Osie X\n",
    "train_dates = station_data['Date'][:len(train_data)]\n",
    "test_dates = station_data['Date'][len(train_data):len(train_data) + len(test_data)]\n",
    "\n",
    "# Okno wykresów\n",
    "fig, axes = plt.subplots(figsize=(36, 32), nrows=3, ncols=1, gridspec_kw={'hspace': 0.3})\n",
    "months_locator = MonthLocator()\n",
    "months_fmt = DateFormatter(\"%b\")\n",
    "years_locator = YearLocator()\n",
    "years_fmt = DateFormatter(\"%Y\")\n",
    "\n",
    "# Wykres predykcji\n",
    "axes[0].plot(train_dates, train_data['GŁOGÓW'], color='b', label='Faktyczne dane', linewidth=2)\n",
    "axes[0].plot(train_dates, model_prediction, 'r', label='Model', linewidth=2)\n",
    "axes[0].plot(test_dates, test_data['GŁOGÓW'], color='g', label='Faktyczne dane (test)', linewidth=2)\n",
    "axes[0].plot(test_dates, test_prediction, color='m', label='Model (test)', linewidth=2)\n",
    "set_common_plot_properties(0, 'Predykcja poziomu wody w Głogowie', 'Poziom wody (cm)')\n",
    "\n",
    "# Wykres błędu bezwzględnego\n",
    "axes[1].plot(train_dates, train_absolute_error, color='b', label='Błąd bezwzględny', linewidth=2)\n",
    "axes[1].plot(test_dates, test_absolute_error, color='r', label='Błąd bezwzględny (test)', linewidth=2)\n",
    "set_common_plot_properties(1, 'Błąd bezwzględny', 'Błąd bezwzględny')\n",
    "\n",
    "# Wykres błędu względnego\n",
    "axes[2].plot(train_dates, train_relative_error, color='b', label='Błąd względny', linewidth=2)\n",
    "axes[2].plot(test_dates, test_relative_error, color='r', label='Błąd względny (test)', linewidth=2)\n",
    "set_common_plot_properties(2, 'Błąd względny', 'Błąd względny')\n",
    "\n",
    "# Wyświetlenie wykresów\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Korelacje Pearsona między stacjami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maksymalna wartość przesunięcia w czasie jednej stacji wobec drugiej, ustawiona na 7 dni (co jest sporym zapasem — ręczna analiza wykazała, że odległość między peakami poziomu wody w stacjach najbardziej oddalonych od Głogowa a stacją w Głogowie rzadko przekraczała 3 dni). Można łatwo zaobserwować trendy w zmienności współczynników wraz ze zmianą przesunięcia w czasie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcja do liczenia korelacji Pearsona między dwiema stacjami\n",
    "def correlation_between_stations(station_1, station_2, lag):\n",
    "    station_1_id = stations.index(station_1.upper())\n",
    "    station_2_id = stations.index(station_2.upper())\n",
    "    correlation = lagged_dfs[lag][station_1_id]['B00020S'].corr(lagged_dfs[0][station_2_id]['B00020S'])\n",
    "    return round(correlation, 4)\n",
    "\n",
    "# Stacje\n",
    "stations = ['GŁOGÓW', 'ŚCINAWA', 'MALCZYCE', 'BRZEG DOLNY', 'OŁAWA', 'BRZEG', 'RACIBÓRZ-MIEDONIA', 'KRZYŻANOWICE', 'OLZA', 'CHAŁUPKI']\n",
    "\n",
    "# Grupowanie po dniach i stacjach\n",
    "data_grouped = data.groupby(['Date', 'Station'])['B00020S'].mean().reset_index()\n",
    "\n",
    "# Maksymalny lag\n",
    "max_lag = 7\n",
    "\n",
    "# Lista od 0 do max_lag\n",
    "lags = range(max_lag + 1)\n",
    "\n",
    "# Dwuwymiarowa lista zlagowanych dataframe'ów stacji\n",
    "# Dostęp do wybranej stacji i lagu: lagged_dfs[lag][id_stacji np. 0 dla Głogowa]\n",
    "start_date = '2008-01-08'\n",
    "end_date = '2023-09-30'\n",
    "lagged_dfs =[[data_grouped[(data_grouped['Date']\n",
    "                .between(\n",
    "                    pd.to_datetime(start_date) - pd.DateOffset(days=lag),\n",
    "                    pd.to_datetime(end_date) - pd.DateOffset(days=lag)\n",
    "                ))&(data_grouped['Station'] == station)].reset_index(drop=True) for station in stations]for lag in lags\n",
    "             ]\n",
    "\n",
    "# Lista stacji, dla których chcemy obliczyć korelację Pearsona względem Głogowa\n",
    "stations_to_calculate_corr = stations.remove('GŁOGÓW')\n",
    "\n",
    "# Wyświetlanie korelacji Pearsona\n",
    "for station in stations_to_calculate_corr:\n",
    "    print(f\"\\nWspółczynnik korelacji Pearsona liczony na podstawie poziomu wody w stacjach: {station.capitalize()} - Głogów\")\n",
    "    for lag in lags:\n",
    "        print(f\"Lag: {lag}, p = {correlation_between_stations(station, 'Głogów', lag)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przesunięcie czasowe stacji (w dniach) względem Głogowa dające najwyższy (prawie najwyższy) współczynnik korelacji:\n",
    "\n",
    "**Chałupki** - 3 (2) \\\n",
    "**Olza** - 4 (5) - można też spróbować wziąć 3, patrząc na współczynnik bardziej oddalonych od Głogowa Chałupek\\\n",
    "**Krzyżanowice** - 3 (2) \\\n",
    "**Racibórz-Miedonia** - 2 (3) \\\n",
    "**Brzeg** - 2 (1) \\\n",
    "**Oława** - 2 (1) \\\n",
    "**Brzeg Dolny** - 1 (2) \\\n",
    "**Malczyce** - 2 (3) - można też spróbować wziąć 1, patrząc na współczynniki bardziej oddalonych od Głogowa Oławy i Brzegu Dolnego \\\n",
    "**Ścinawa** - 1 (0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
